# Lightgmb

### xgboost

首先，空间消耗大。这样的算法需要保存数据的特征值，还保存了特征排序的结果（例如排序后的索引，为了后续快速的计算分割点），这里需要消耗训练数据两倍的内存。

其次，时间上也有较大的开销，在遍历每一个分割点的时候，都需要进行分裂增益的计算，消耗的代价大。

最后，对cache优化不友好。在预排序后，特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化。同时，在每一层长树的时候，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样，也会造成较大的cache miss。

### lightgbm优化:
* 基于Histogram的决策树算法
* 带深度限制的Leaf-wise的叶子生长策略
* 直方图做差加速
* 直接支持类别特征(Categorical Feature)
* Cache命中率优化
* 基于直方图的稀疏特征优化
* 多线程优化

[优化细节][1]

[1]: http://www.msra.cn/zh-cn/news/blogs/2017/01/lightgbm-20170105.aspx
